---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "README-"
)
```

## cutpointr

[![Travis-CI Build Status](https://travis-ci.org/Thie1e/cutpointr.svg?branch=master)](https://travis-ci.org/Thie1e/cutpointr)
[![AppVeyor Build Status](https://ci.appveyor.com/api/projects/status/github/Thie1e/cutpointr?branch=master&svg=true)](https://ci.appveyor.com/project/Thie1e/cutpointr)
[![Project Status: Active - The project has reached a stable, usable state and is being actively developed.](http://www.repostatus.org/badges/latest/active.svg)](http://www.repostatus.org/#active)
[![codecov](https://codecov.io/github/thie1e/cutpointr/branch/master/graphs/badge.svg)](https://codecov.io/github/thie1e/cutpointr) 

cutpointr is an R package for tidy calculation of "optimal" cutpoints. It 
supports several methods for calculating cutpoints and includes several 
metrics that can be maximized or minimized by selecting a cutpoint. Additionally,
cutpointr can automatically bootstrap the variability of the optimal 
cutpoints and return out-of-bag estimates of various metrics.

## Installation

```{r, eval = FALSE}
devtools::install_github("thie1e/cutpointr")
```

## Features

- Calculation of "optimal" cutpoints in binary classification tasks
- Tidy output, integrates well with functions from the tidyverse
- Bootstrapping for simulating the cutpoint variability and for getting 
out-of-bag estimates of various metrics (as a form of cross validation)
- Multiple methods for calculating cutpoints
- Multiple metrics can be chosen for maximization / minimization
- Standard/Nonstandard evaluation of the function arguments

## Calculating cutpoints

The included methods for calculating cutpoints are:

- `maximize_metric`: Maximize the metric function
- `minimize_metric`: Minimize the metric function
- `maximize_loess_metric`: Maximize the metric function after LOESS smoothing
- `minimize_loess_metric`: Minimize the metric function after LOESS smoothing
- `oc_manual`: Specify the cutoff value manually
- `oc_youden_kernel`: Maximize the Youden-Index after kernel smoothing
the distributions of the two classes
- `oc_youden_normal`: Maximize the Youden-Index parametrically
assuming normally distributed data in both classes
- `oc_OptimalCutpoints`: A tidy wrapper for optimal.cutpoints from the OptimalCutpoints package.
Supply an additional `oc_metric` argument with the method choice corresponding
to a method from the OptimalCutpoints package

The included metrics to be used with the minimization and maximization methods 
are:

- `accuracy`: Fraction correctly classified
- `abs_d_sesp`: The absolute difference of sensitivity and specificity
- `abs_d_ppvnpv`: The absolute difference between positive predictive
value (PPV) and negative predictive value (NPV)
- `cohens_kappa`: Cohen's Kappa
- `sum_sens_spec`: sensitivity + specificity
- `sum_ppvnpv`: The sum of positive predictive value (PPV) and negative
predictive value (NPV)
- `prod_sens_spec`: sensitivity * specificity
- `prod_ppvnpv`: The product of positive predictive value (PPV) and 
negative predictive value (NPV)
- `youden`: Youden- or J-Index = sensitivity + specificity - 1
- `odds_ratio`: (Diagnostic) odds ratio
- `p_chisquared`: The p-value of a chi-squared test on the confusion
matrix
- `cost_misclassification`: The sum of the misclassification cost of
false positives and false negatives. Additional arguments: cost_fp, cost_fn
- `total_utility`: The total utility of true / false positives / negatives.
Additional arguments: utility_tp, utility_tn, cost_fp, cost_fn

cutpointr makes use of nonstandard evaluation for higher usability and to
allow for easy transformation of the variables. The inputs to the arguments
`method` and `metric` are functions so that user-defined functions can easily
be supplied instead of the built in ones.

## Applications

To showcase the functionality, we'll use the included `suicide` data set.

```{r}
library(cutpointr)
data(suicide)
head(suicide)
opt_cut <- cutpointr(suicide, dsi, suicide)
opt_cut
```

cutpointr makes assumptions about the direction of the dependency between 
class and x, if `direction` and / or `pos_class` or `neg_class` are not
specified. The same result can be achieved by manually defining `direction` and
the positive / negative classes which is slightly faster:

```{r}
opt_cut <- cutpointr(suicide, dsi, suicide, direction = ">=", pos_class = "yes",
                     neg_class = "no", method = maximize_metric, metric = youden)
opt_cut
```

`opt_cut` is a tidy data frame that returns the input data in a 
nested tibble. Methods for summarizing and plotting the data and
results are included:

```{r}
summary(opt_cut)
plot(opt_cut)
```

Predictions for new data can be made using `predict`:

```{r}
predict(opt_cut, newdata = data.frame(dsi = 0:5))
```

### Separate subgroups

Cutpoints can be separately estimated on a subgroup, gender in this case:

```{r}
opt_cut <- cutpointr(suicide, dsi, suicide, gender)
opt_cut
summary(opt_cut)
plot(opt_cut)
```

### Bootstrapping

If `boot_runs` is larger zero, cutpointr will carry out the usual cutpoint
calculation on the full sample, just as before, and additionally on 
`boot_runs` bootstrap samples. 

```{r}
set.seed(12)
opt_cut <- cutpointr(suicide, dsi, suicide, boot_runs = 200)
opt_cut
```

The returned object has the additional column `boot` which is a nested tibble that
includes the cutpoints per bootstrap sample along with the metric calculated using 
the function in `metric` and
a number of additional metrics. The values in the second column that are calculated
using the function in `metric` represent out-of-bag results. The other default
metrics are suffixed by `_b` to indicate in-bag results or `_oob` to indicate
out-of-bag results:

```{r}
opt_cut$boot
```

The summary and plots include additional elements:

```{r}
summary(opt_cut)
plot(opt_cut)
```

If a subgroup is given, the bootstrapping is carried out separately for every
subgroup:

```{r}
set.seed(12)
opt_cut <- cutpointr(suicide, dsi, suicide, gender, boot_runs = 200)
opt_cut
summary(opt_cut)
plot(opt_cut)
```

### Parallelized bootstrapping

Using `foreach` and `doRNG` the bootstrapping can easily be parallelized. The
`doRNG` package is being used to make the bootstrap sampling reproducible. It may
be preferable for long running tasks to specify `direction` and `pos_class` 
and / or `neg_class` manually to speed up `cutpointr`.

```{r}
if (suppressPackageStartupMessages(require(doSNOW) & require(doRNG))) {
  cl <- makeCluster(2) # 2 cores
  registerDoSNOW(cl)
  registerDoRNG(12) # Reproducible parallel loops using doRNG
  opt_cut <- cutpointr(suicide, dsi, suicide, gender, pos_class = "yes",
                 direction = ">=", boot_runs = 200, allowParallel = TRUE)
  stopCluster(cl)
  opt_cut
}
```

### LOESS smoothing for selecting a cutpoint

When using `maximize_metric` and `minimize_metric` the optimal cutpoint is 
selected by searching the maximum or minimum of the metric function. For 
example, we would like to optimize the misclassification cost. Since false 
negatives (a suicide attempt was not anticipated) the minimum of this function
is selected as the 'optimal' cutpoint:

```{r}
opt_cut <- cutpointr(suicide, dsi, suicide, gender, method = minimize_metric,
                     metric = misclassification_cost, cost_fp = 1, cost_fn = 10)
opt_cut
```

```{r}
plot_metric(opt_cut)
```

As this 'optimal' cutpoint may depend on minor differences between the 
possible cutoffs, a smoothed version of the function of metric values by
cutpoint value might be desired, especially in small samples. The
`minimize_loess_metric` and `maximize_loess_metric` functions can be used
to smooth the function so that the 'optimal' cutpoint is selected based on the
smoothed metric values. Options to modify the smoothing, which is based on
`loess.as` from the `fANCOVA` package, include:

- `criterion`: the criterion for automatic smoothing parameter selection: "aicc" denotes bias-corrected AIC criterion, "gcv" denotes generalized cross-validation.
- `degree`: the degree of the local polynomials to be used. It can be 0, 1 or 2.
- `family`: if "gaussian" fitting is by least-squares, and if "symmetric" a re-descending M estimator is used with Tukey's biweight function.
- `user.span`: the user-defined parameter which controls the degree of smoothing.

Using the values for the LOESS smoothing of `criterion = "aicc"`, `degree = 2`, 
`family = "symmetric"`, and `user.span = 0.7` we get the following smoothed
versions of the above metrics:

```{r}
opt_cut <- cutpointr(suicide, dsi, suicide, gender, 
                     method = minimize_loess_metric,
                     criterion = "aicc", family = "symmetric", 
                     degree = 2, user.span = 0.7,
                     metric = misclassification_cost, cost_fp = 1, cost_fn = 10)
opt_cut
```

```{r}
plot_metric(opt_cut)
```


The 'optimal' cutpoint for the female subgroup changes to 3. Note that there 
are no reliable rules for selecting the 'best' smoothing parameters. Notably,
the LOESS smoothing is sensitive to the number of unique cutpoints. A large 
number of unique cutpoints generally leads to a more volatile curve of 
metric values by cutpoint value, even after smoothing. 

The unsmoothed metric values are returned in `opt_cut$roc_curve` in the column
`m_unsmoothed`.

## Nonstandard evaluation and transforming variables

The arguments to `cutpointr` do not need to be enclosed in quotes. This is 
possible thanks to nonstandard evaluation of the arguments, which are 
evaluated in `data`. Alternatively, the arguments *can* be enclosed in quotes.
In that case, transforming the data within the function call is not possible
and `method` and `metric` functions that are enclosed in quotes are only looked
up within the cutpointr package. As an example of a transformation of the
`x`, `class` and `subgroup` variable consider:

```{r}
set.seed(12)
opt_cut <- cutpointr(suicide, log(dsi + 1), suicide == "yes",
    subgroup = dsi %% 2 == 0, boot_runs = 30)
opt_cut
summary(opt_cut)
plot(opt_cut)
predict(opt_cut, newdata = data.frame(dsi = 0:5))
```

Functions that use nonstandard evaluation are usually not suitable for 
programming with. The use of nonstandard evaluation often leads to scoping 
problems and subsequent obvious as well as possibly subtle errors. Similar to
tidyverse functions, cutpointr offers a variant that uses standard evaluation
which is suffixed by `_`. Thus, `cutpointr_` is suitable for programming with.
It gives the same results as `cutpointr`, of course, but does not support 
transforming variables as above. 

```{r}
identical(cutpointr(suicide, dsi, suicide), cutpointr_(suicide, "dsi", "suicide"))
```


## cutpointr in the tidyverse

Since cutpointr outputs a tidy data frame and `data` is the first argument,
it can be conveniently used in conjunction with various functions from the "tidyverse". 

```{r}
opt_cut <- cutpointr(suicide, dsi, suicide)
class(opt_cut) # the result is also a data.frame

suppressMessages(library(dplyr))
suppressMessages(library(tidyr))
suppressMessages(library(purrr))
suppressMessages(library(ggplot2))
suicide %>%
    group_by(gender) %>%
    nest() %>%
    mutate(cutmod1 = map(data, function(x) cutpointr(x, dsi, suicide,
                                                     metric = accuracy)),
           cutmod2 = map(data, function(x) cutpointr(x, dsi, suicide,
                                                     metric = sum_sens_spec)))
```

### Accessing `data`, `roc_curve`, and `boot` 

The object returned by `cutpointr` is of the classes `cutpointr`, `tbl_df`,
`tbl`, and `data.frame`. Thus, it can be handled like a usual tibble. The
columns `data`, `roc_curve`, and `boot` are nested tibbles, which means that
these are list columns whose elements are tibbles. They can either be accessed
using `[` or by using functions from the tidyverse.

```{r}
# Extracting the bootstrap results
set.seed(123)
opt_cut <- cutpointr(suicide, dsi, suicide, boot_runs = 30)
# Using base R
summary(opt_cut$boot[[1]]$optimal_cutpoint)
# Using dplyr
opt_cut %>% select(boot) %>% unnest %>% select(optimal_cutpoint) %>% summary
```

If subgroups were given, there will be one row per subgroup and the function 
that accesses the data should be mapped to every row or the data should be 
grouped by subgroup.

```{r}
set.seed(123)
opt_cut <- cutpointr(suicide, dsi, suicide, gender, boot_runs = 30)
opt_cut %>% 
    select(subgroup, boot) %>%
    unnest %>%
    group_by(subgroup) %>%
    summarise(m = mean(optimal_cutpoint))
opt_cut %>%
    select(subgroup, boot) %>% 
    mutate(summary_b = map(boot, function(x) data.frame(min = min(x$optimal_cutpoint),
                                                        mean = mean(x$optimal_cutpoint),
                                                        max = max(x$optimal_cutpoint)))) %>% 
    select(-boot) %>%
    unnest
```



## Plotting

cutpointr includes several convenience functions for plotting data from a 
`cutpointr` object. These include:

- `plot_cut_boot`: Plot the bootstrapped distribution of optimal cutpoints
- `plot_metric`: If `maximize_metric` or `minimize_metric` was used this function
plots all possible cutoffs on the x-axis vs. the respective metric values on
the y-axis
- `plot_metric_boot`: Plot the distribution of out-of-bag metric values
- `plot_precision_recall`: Plot the precision recall curve
- `plot_roc`: Plot the ROC curve
- `plot_x`: Plot the distribution of the predictor variable

```{r, fig.width=4, fig.height=3}
opt_cut <- cutpointr(suicide, dsi, suicide, gender, method = minimize_metric,
                     metric = abs_d_sesp, boot_runs = 100)
opt_cut
plot_cut_boot(opt_cut)
plot_metric(opt_cut)
plot_metric_boot(opt_cut)
plot_precision_recall(opt_cut)
plot_roc(opt_cut)
plot_x(opt_cut)
```

All plot functions, except for the standard plot method, return `ggplot` objects
than can be further modified. For example, changing labels, title, and the theme
can be achieved this way:

```{r}
p <- plot_x(opt_cut)
p + ggtitle("Distribution of dsi") + theme_minimal() + xlab("Depression score")
```


### Manual plotting

Since cutpointr returns a tidy data frame with the supplied data, bootstrap
results and the ROC curve in nested tibbles these data can coveniently be 
plotted manually. This offers additional ways of tweaking these plots as well
as the possibility to plot results that are not included in `plot`, 
`plot_metric`, `plot_cut_boot`, `plot_metric_boot` or `plot_roc`. The relevant
nested tibbles are in the columns `data`, `roc_curve` and `boot`. The following
is an example of accessing and plotting the grouped data.

```{r}
set.seed(123) # Some missing values expected
opt_cut <- cutpointr(suicide, dsi, suicide, gender, boot_runs = 100)
head(opt_cut$data)

opt_cut %>% 
    select(data, subgroup) %>% 
    unnest %>% 
    ggplot(aes(x = suicide, y = dsi)) + 
    geom_boxplot(alpha = 0.3) + facet_grid(~subgroup)
```

### ROC curve only

When running `cutpointr` a ROC curve is by default returned in the column `roc_curve`.
This ROC curve can be plotted using `plot_roc`. Alternatively, if only the
ROC curve is desired and no cutpoint needs to be calculated, the ROC curve
can be plotted using the `roc` function and, for example, **ggplot2**. Note that
the `roc` function, unlike `cutpointr`, does not determine `direction`, `pos_class` or `neg_class`
automatically and does not support nonstandard evaluation, so the function
arguments have to be enclosed in quotation marks.

```{r}
roc(data = suicide, x = "dsi", class = "suicide", 
    pos_class = "yes", neg_class = "no") %>% 
    ggplot(aes(x = fpr, y = tpr)) + geom_line() + geom_point()
```


## User-defined method and metric functions

User defined functions can be supplied to method. 
To define a new method function, create a function that may take
as input(s):

- `data`: A data frame or tbl_df
- `x`: (character) The name of the predictor or independent variable
- `class`: (character) The name of the class or dependent variable
- `metric_func`: A function for calculating a metric, e.g. accuracy. Note
 that the method function does not necessarily have to accept this argument
- `pos_class`: The positive class
- `neg_class`: The negative class
- `direction`: ">=" if the positive class has higher x values, "<=" otherwise
- `...`: Further arguments that are passed to `metric` or that can be captured
inside of `method`

The function should return a data frame or tbl_df with
one row, the column "optimal_cutpoint", and an optinal column with an arbitraty name
with the metric value at the optimal cutpoint.

For example, a function for choosing the cutpoint as the mean of the independent
variable could look like this:

```{r, eval = FALSE}
mean_cut <- function(data, x, ...) {
    oc <- mean(unlist(data[, x]))
    return(data.frame(optimal_cutpoint = oc))
}
```

Since no metric is returned, `Sum_Sens_Spec`, the sum of sensitivity and 
specificity, is returned as the extra metric column in addition to accuracy, 
sensitivity and specificity.

Some `method` functions that make use of the additional arguments (that are 
captured by `...` in `mean_cut`) are already included in cutpointr, see
the list at the top. Since these functions are arguments to `cutpointr` 
their code can be accessed by simply typing their name, e.g.:

```{r}
oc_youden_normal
```


User defined **metric functions** can be used as well. They are mainly useful in
conjunction with `method = maximize_metric` or `method = minimize_metric`. 
In case of a different `method` function `metric` will only be used as the main
out-of-bag metric when plotting the result. The `metric` function should 
accept the following inputs as vectors:

- `tp`: Vector of true positives
- `fp`: Vector of false positives
- `tn`: Vector of true negatives
- `fn`: Vector of false negatives
- `...`: Further arguments

The function should return a **matrix with one column**
and the inputs (`tp`, `fp`, `tn`, and `fn`) are **vectors**. If the column is named,
the name will be included in the output and plots. Avoid using names that
are identical to the column names that are by default returned by cutpointr.
The code of the included metric functions can be accessed by simply typing their name.

For example, this is the `accuracy` metric function:

```{r}
misclassification_cost
```


## Benchmarks

To offer a comparison to established solutions,
`cutpointr` will be benchmarked against `optimal.cutpoints` 
from the `OptimalCutpoints` package and a custom function that relies on 
functions from the `ROCR` package. By generating data of different sizes 
the benchmarks will offer a comparison of the scalability of the different 
solutions.

Using `prediction` and `performance` from the `ROCR` package, we can write a 
function for computing the cutpoint that maximizes the sum of sensitivity and
specificity:

```{r}
# Return cutpoint that maximizes the sum of sensitivity and specificiy
rocr_sensspec <- function(x, class) {
    pred <- ROCR::prediction(x, class)
    perf <- ROCR::performance(pred, "sens", "spec")
    sens <- slot(perf, "y.values")[[1]]
    spec <- slot(perf, "x.values")[[1]]
    cut <- slot(perf, "alpha.values")[[1]]
    cut[which.max(sens + spec)]
}
```

The benchmarking will be carried out using the `microbenchmark` package and
generated data. The values of the `x` variable are drawn from a normal distribution
which leads to a lot more unique values than were encountered before in the 
`suicide` data. Accordingly, the search for an optimal cutpoint is much more 
demanding, depending on the size of the data.

Benchmarks are run for sample sizes of 100, 500, 1000, 10000, 50000 and 100000.
For low sample sizes, cutpointr slower than the other
solutions. While this should be of no practical importance, cutpointr scales
more favorably than the other solutions. For sample sizes > 100000 cutpointr
is a little faster than the simple function based on `ROCR`. Both of these 
solutions are generally faster than `OptimalCutpoints` with the exception of
small samples. `OptimalCutpoints` had to be excluded from benchmarks with 
more than 10000 observations due to its high memory requirements.


```{r}
n <- 100
set.seed(123)
dat <- data.frame(x = rnorm(n), y = sample(c(0:1), size = n, replace = TRUE))
bench_100 <- microbenchmark::microbenchmark(
    cutpointr(dat, x, y, pos_class = 1, neg_class = 0, 
              direction = ">=", metric = youden),
    rocr_sensspec(dat$x, dat$y),
    optimal.cutpoints(X = "x", status = "y", tag.healthy = 0, methods = "Youden",
                      data = dat)
)

n <- 500
set.seed(123)
dat <- data.frame(x = rnorm(n), y = sample(c(0:1), size = n, replace = TRUE))
bench_500 <- microbenchmark::microbenchmark(
    cutpointr(dat, x, y, pos_class = 1, neg_class = 0,
              direction = ">=", metric = youden),
    rocr_sensspec(dat$x, dat$y),
    optimal.cutpoints(X = "x", status = "y", tag.healthy = 0, methods = "Youden",
                      data = dat)
)

n <- 1000
set.seed(123)
dat <- data.frame(x = rnorm(n), y = sample(c(0:1), size = n, replace = TRUE))
bench_1000 <- microbenchmark::microbenchmark(
    cutpointr(dat, x, y, pos_class = 1, neg_class = 0,
              direction = ">=", metric = youden),
    rocr_sensspec(dat$x, dat$y),
    optimal.cutpoints(X = "x", status = "y", tag.healthy = 0, methods = "Youden",
                      data = dat)
)

n <- 10000
set.seed(123)
dat <- data.frame(x = rnorm(n), y = sample(c(0:1), size = n, replace = TRUE))
bench_10000 <- microbenchmark::microbenchmark(
    cutpointr(dat, x, y, pos_class = 1, neg_class = 0,
              direction = ">=", metric = youden),
    rocr_sensspec(dat$x, dat$y),
    optimal.cutpoints(X = "x", status = "y", tag.healthy = 0, methods = "Youden",
                      data = dat),
    times = 10
)

n <- 50000
set.seed(123)
dat <- data.frame(x = rnorm(n), y = sample(c(0:1), size = n, replace = TRUE))
bench_50000 <- microbenchmark::microbenchmark(
    cutpointr(dat, x, y, pos_class = 1, neg_class = 0,
              direction = ">=", metric = youden),
    rocr_sensspec(dat$x, dat$y),
    times = 100
)

n <- 100000
set.seed(123)
dat <- data.frame(x = rnorm(n), y = sample(c(0:1), size = n, replace = TRUE))
bench_100000 <- microbenchmark::microbenchmark(
    cutpointr(dat, x, y, pos_class = 1, neg_class = 0,
              direction = ">=", metric = youden),
    rocr_sensspec(dat$x, dat$y),
    times = 100
)

results <- rbind(data.frame(time = summary(bench_100)$median,
                            solution = summary(bench_100)$expr, 
                            n = 100),
                 data.frame(time = summary(bench_500)$median,
                            solution = summary(bench_500)$expr, 
                            n = 500),
                 data.frame(time = summary(bench_1000)$median,
                            solution = summary(bench_1000)$expr, 
                            n = 1000),
                 data.frame(time = summary(bench_10000)$median,
                            solution = summary(bench_10000)$expr, 
                            n = 10000),
                 data.frame(time = summary(bench_50000)$median,
                            solution = summary(bench_50000)$expr, 
                            n = 50000),
                 data.frame(time = summary(bench_100000)$median,
                            solution = summary(bench_100000)$expr, 
                            n = 100000))
results$solution <- as.character(results$solution)
results$solution[grep(pattern = "cutpointr", x = results$solution)] <- "cutpointr"
results$solution[grep(pattern = "rocr", x = results$solution)] <- "ROCR"
results$solution[grep(pattern = "optimal", x = results$solution)] <- "OptimalCutpoints"

ggplot(results, aes(x = n, y = time, col = solution, shape = solution)) +
    geom_point(size = 3) + geom_line() +
    scale_y_log10() + scale_x_log10() + 
    ggtitle("Benchmark results", "n = 100, 500, 1000, 10000, 50000, 100000") +
    ylab("Median time (milliseconds, log scale)") + xlab("log(n)")
```

